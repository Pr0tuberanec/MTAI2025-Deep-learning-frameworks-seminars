{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuDotMn6HTUQ"
      },
      "source": [
        "# TensorRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30JaAa7DJ3_D"
      },
      "source": [
        "## Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wYjQs3e6RWz",
        "outputId": "86624181-0dc9-43ef-f361-81df79e9ba37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch                                    2.8.0+cu126\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.8.0+cu126\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.23.0+cu126\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip list | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzqMCXd7KCwT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjbB2JHo6-3A"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch-tensorrt==2.8.0 -f https://github.com/pytorch/TensorRT/releases/expanded_assets/2.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFFx7LYUG6Qo"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOW61jT5KKix"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch_tensorrt\n",
        "\n",
        "testing_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "testing_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbwkIeziKqDT"
      },
      "outputs": [],
      "source": [
        "calibrator = torch_tensorrt.ptq.DataLoaderCalibrator(\n",
        "    testing_dataloader,\n",
        "    cache_file=\"./calibration.cache\",\n",
        "    use_cache=True,\n",
        "    algo_type=torch_tensorrt.ptq.CalibrationAlgo.ENTROPY_CALIBRATION_2,\n",
        "    device=torch.device(\"cuda:0\"),\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8TAxxJDKrXC"
      },
      "outputs": [],
      "source": [
        "trt_mod = torch_tensorrt.compile(model, inputs=[torch_tensorrt.Input((1, 3, 32, 32))],\n",
        "                                    enabled_precisions={torch.float, torch.half, torch.int8},\n",
        "                                    calibrator=calibrator,\n",
        "                                    device={\n",
        "                                         \"device_type\": torch_tensorrt.DeviceType.GPU,\n",
        "                                         \"gpu_id\": 0,\n",
        "                                         \"dla_core\": 0,\n",
        "                                         \"allow_gpu_fallback\": False,\n",
        "                                         \"disable_tf32\": False\n",
        "                                     })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTw2cquwMMQW"
      },
      "source": [
        "Если нужно переквантизировать модель, то можно использовать кэш калибратора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AgMr5yuKdKD"
      },
      "outputs": [],
      "source": [
        "calibrator = torch_tensorrt.ptq.CacheCalibrator(\"./calibration.cache\")\n",
        "\n",
        "trt_mod = torch_tensorrt.compile(model, inputs=[torch_tensorrt.Input([1, 3, 32, 32])],\n",
        "                                      enabled_precisions={torch.float, torch.half, torch.int8},\n",
        "                                      calibrator=calibrator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FCzs4kJG6pH"
      },
      "source": [
        "# Задание на семинар\n",
        "\n",
        "Нужно квантизировать при помощи TensorRT любую модель из torchvision или timm (hugging-face) до int8 и до float16. Затем нужно проверить скорость работы получившихся вариаций модели (float32 - исходная, float16 и int8) и их размер. Результаты привести в блокноте."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "hCGlQ6o4SLDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt-cu12  torch-tensorrt==2.8.0 -f https://github.com/pytorch/TensorRT/releases/expanded_assets/2.8.0"
      ],
      "metadata": {
        "id": "arRsdyrtQnRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zchnak2Pq_hH"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "from torchao.utils import (\n",
        "    benchmark_model,\n",
        "    unwrap_tensor_subclass,\n",
        ")\n",
        "from torch import nn\n",
        "import torch\n",
        "import tensorrt\n",
        "\n",
        "import os\n",
        "\n",
        "def benchmark_speed(model_orig: nn.Module,\n",
        "                    model_quant: nn.Module,\n",
        "                    example_inputs: torch.Tensor,\n",
        "                    num_runs: int = 100):\n",
        "    torch._dynamo.reset()\n",
        "    orig_time = benchmark_model(model_orig, num_runs, example_inputs)\n",
        "    quant_time = benchmark_model(model_quant, num_runs, example_inputs)\n",
        "\n",
        "    print(\"orig mean time: %0.3f ms\" % orig_time)\n",
        "    print(\"quant mean time: %0.3f ms\" % quant_time)\n",
        "    print(\"speedup: %0.1fx\" % (orig_time / quant_time))\n",
        "    torch._dynamo.reset()\n",
        "\n",
        "\n",
        "def benchmark_size(model_orig: nn.Module, model_quant: nn.Module):\n",
        "    torch.save(model_orig, \"/tmp/orig_model.pt\")\n",
        "    torch.save(model_quant, \"/tmp/quant_model.pt\")\n",
        "    quant_model_size_mb = os.path.getsize(\"/tmp/quant_model.pt\") / 1024 / 1024\n",
        "    orig_model_size_mb = os.path.getsize(\"/tmp/orig_model.pt\") / 1024 / 1024\n",
        "\n",
        "    print(\"quant model size: %.2f MB\" % quant_model_size_mb)\n",
        "\n",
        "    print(\"original model size: %.2f MB\" % orig_model_size_mb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4WUsTPwr33l"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model('vit_base_patch14_dinov2.lvd142m').cuda()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ngduY-G2o4L"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "testing_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            transforms.Resize((518, 518))\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "testing_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEA_HYmk3Dcs",
        "outputId": "2820579f-4109-4e54-acae-dac5350f4b9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-3108842424.py:3: DeprecationWarning: Int8 PTQ Calibrator has been deprecated by TensorRT, please plan on porting to a NVIDIA Model Optimizer Toolkit based workflow. See: https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/vgg16_ptq.html for more details\n",
            "  calibrator = DataLoaderCalibrator(\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch_tensorrt.ts.ptq import DataLoaderCalibrator, CalibrationAlgo\n",
        "\n",
        "calibrator = DataLoaderCalibrator(\n",
        "    testing_dataloader,\n",
        "    cache_file=\"./calibration.cache\",\n",
        "    use_cache=False,\n",
        "    algo_type=CalibrationAlgo.ENTROPY_CALIBRATION_2,\n",
        "    device=torch.device(\"cuda:0\"),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TdHXM3J3ECF"
      },
      "outputs": [],
      "source": [
        "quantized_model = torch_tensorrt.compile(model, inputs=[torch_tensorrt.Input((1, 3, 518, 518))],\n",
        "                                    enabled_precisions={torch.float, torch.half, torch.int8},\n",
        "                                    # calibrator=calibrator,\n",
        "                                    device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFpIPCB8_LLe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_NJ2cMc4Ghs",
        "outputId": "10e80a64-d77c-44aa-fd9d-17ed554375e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quant model size: 937.36 MB\n",
            "original model size: 330.39 MB\n"
          ]
        }
      ],
      "source": [
        "benchmark_size(model, quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XNTxeqX5FcZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ii5QQsl5Fex"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QX1hTWc5Fhe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}